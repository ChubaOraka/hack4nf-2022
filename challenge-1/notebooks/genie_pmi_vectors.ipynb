{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7872be71",
   "metadata": {},
   "source": [
    "# Create gene vectors from mutations and CNA data\n",
    "\n",
    "Use cooccurrence statistics to create gene vectors. \n",
    "\n",
    "[Stop Using word2vec](https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/)\n",
    "\n",
    "[PMI Word Vectors from Wikipedia](https://www.kaggle.com/code/kenshoresearch/kdwd-pmi-word-vectors)\n",
    "\n",
    "[Improving Distributional Similarity with Lessons Learned from Word Embeddings](https://aclanthology.org/Q15-1016/) (LGD15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab848b",
   "metadata": {},
   "source": [
    "# Create Gene Embeddings from Tumor Sample \"Sentences\" \n",
    "\n",
    "We are going to create Gene vectors by treating them like words in sentences.\n",
    "We can then combine these to make tumor sample embeddings.\n",
    "The descriptions below are copied from LGD15. In their work, they refer \"words and their contexts\". \n",
    "We will map these idess to \"genes and their contexts\". \n",
    "To create our gene embeddings we will, \n",
    "\n",
    "* create gene-gene co-occurrence matrices. \n",
    "* calculate a pointwise mutual information matrices. \n",
    "* reduce the dimensionality using singular value decomposition. \n",
    "\n",
    "\n",
    "# Pointwise Mutual Information Matrices (Notation from LGD15)\n",
    "\n",
    "\n",
    "## Notation\n",
    "\n",
    "\n",
    "We assume a collection of words $w \\in V_W$ and their\n",
    "contexts $c \\in V_C$, where $V_W$ and $V_C$\n",
    "are the word and context vocabularies, and denote\n",
    "the collection of observed word-context pairs as $D$.\n",
    "\n",
    "We use $\\#(w,c)$ to denote the number of times the pair\n",
    "$(w,c)$ appears in $D$ and $\\#(w)$ and $\\#(c)$ to denote \n",
    "the number of times $w$ and $c$ occurred in $D$, respectively.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\#(w) = \\sum_{c^{\\prime}} \\#(w, c^{\\prime})\n",
    ", \\quad\n",
    "\\#(c) = \\sum_{w^{\\prime}} \\#(w^{\\prime}, c)\n",
    ", \\quad\n",
    "\\lvert D \\rvert = \\sum_{w,c} \\#(w, c)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{P}(w) = \\frac{\\#(w)}{\\lvert D \\rvert}\n",
    ", \\quad\n",
    "\\hat{P}(c) = \\frac{\\#(c)}{\\lvert D \\rvert}\n",
    ", \\quad\n",
    "\\hat{P}(w,c) = \\frac{\\#(w,c)}{\\lvert D \\rvert}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "## Contexts\n",
    "\n",
    "$D$ is commonly obtained by taking a\n",
    "corpus $w_1$, $w_2$, . . . , $w_n$ and defining the contexts\n",
    "of word $w_i$ as the words surrounding it in an \n",
    "$L$-sized window $w_{i−L}$, . . . , $w_{i−1}$, $w_{i+1}$, . . . , $w_{i+L}$.\n",
    "\n",
    "In our case, the corpus will be genes and their contexts will be \n",
    "other genes that co-occurr in the same sample.  \n",
    "\n",
    "\n",
    "## Definitions\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "PMI(w, c) = \n",
    "\\log \\frac\n",
    "{\\hat{P}(w,c)}\n",
    "{\\hat{P}(w)\\hat{P}(c)} =\n",
    "\\log \\frac\n",
    "{\\#(w,c) \\, \\cdot \\lvert D \\rvert}\n",
    "{\\#(w) \\cdot \\#(c)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "PPMI(w, c) = {\\rm max} \\left[ PMI(w, c), 0 \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "## Context Distribution Smoothing\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "PMI_{\\alpha}(w, c) = \n",
    "\\log \\frac\n",
    "{\\hat{P}(w,c)}\n",
    "{\\hat{P}(w)\\hat{P}_{\\alpha}(c)} = \n",
    "\\log \\frac\n",
    "{\\#(w,c) \\cdot \\sum_{c^{\\prime}} \\#(c^{\\prime})^{\\alpha}}\n",
    "{\\#(w) \\cdot \\#(c)^{\\alpha}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{P}_{\\alpha}(c) = \n",
    "\\frac\n",
    "{\\#(c)^{\\alpha}}\n",
    "{\\sum_{c^{\\prime}} \\#(c^{\\prime})^{\\alpha}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nextgenlp import synapse \n",
    "from nextgenlp import genie\n",
    "from nextgenlp import genie_constants\n",
    "from nextgenlp import embedders\n",
    "from nextgenlp.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNC_PATH = config['Paths']['SYNAPSE_PATH']\n",
    "EMBEDDINGS_PATH = config['Paths']['EMBEDDINGS_PATH']\n",
    "print(SYNC_PATH)\n",
    "print(EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_UNIGRAM_COUNT = 10\n",
    "EMBEDDING_SIZES = [50, 100, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e6681",
   "metadata": {},
   "source": [
    "# RAS Pathway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd32a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ras = pd.read_excel(os.path.join(SYNC_PATH, '../nci-ras-initiative/ras-pathway-gene-names.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_extra(df_ras, embds, unigram_name):\n",
    "    # record RAS pathway membership\n",
    "    df_meta_extra = pd.DataFrame(\n",
    "        [\n",
    "            embds.index_to_unigram[ii]\n",
    "            for ii in range(len(embds.index_to_unigram))\n",
    "        ],\n",
    "        columns=[unigram_name],\n",
    "    )\n",
    "\n",
    "    df_meta_extra = pd.merge(\n",
    "        df_meta_extra,\n",
    "        df_ras[[\"Gene name\"]],\n",
    "        left_on=unigram_name,\n",
    "        right_on=\"Gene name\",\n",
    "        how=\"left\",\n",
    "    ).rename(columns={\"Gene name\": \"path_RAS_flag\"})\n",
    "    bmask = df_meta_extra[\"path_RAS_flag\"].isnull()\n",
    "    df_meta_extra.loc[bmask, \"path_RAS_flag\"] = 0\n",
    "    df_meta_extra.loc[~bmask, \"path_RAS_flag\"] = 1\n",
    "    \n",
    "    return df_meta_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f6be7",
   "metadata": {},
   "source": [
    "# Loop over all options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022c0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4806e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f153c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unigram_name = \"gene\"\n",
    "\n",
    "for genie_version in synapse.VALID_GENIE_VERSIONS:\n",
    "    print(genie_version)\n",
    "\n",
    "    syn_file_paths = synapse.get_file_name_to_path(genie_version=genie_version)\n",
    "    df_gp_wide = genie.read_gene_panels(syn_file_paths[\"gene_panels\"], style=\"wide\")\n",
    "\n",
    "    df_psm_all = genie.read_pat_sam_mut(\n",
    "        syn_file_paths[\"data_clinical_patient\"],\n",
    "        syn_file_paths[\"data_clinical_sample\"],\n",
    "        syn_file_paths[\"data_mutations_extended\"],\n",
    "    )\n",
    "    df_dcs_all = genie.read_clinical_sample(syn_file_paths[\"data_clinical_sample\"])\n",
    "    df_dcs_all = df_dcs_all.loc[df_psm_all[\"SAMPLE_ID\"].unique()]\n",
    "    df_cna_all = genie.read_cna(syn_file_paths[\"data_CNA\"])\n",
    "\n",
    "    print(\"df_psm_all.shape: \", df_psm_all.shape)\n",
    "    print(\"df_dcs_all.shape: \", df_dcs_all.shape)\n",
    "    print(\"df_cna_all.shape: \", df_cna_all.shape)\n",
    "\n",
    "    for subset_name, seq_assay_ids in genie_constants.SEQ_ASSAY_ID_GROUPS.items():\n",
    "        print(subset_name)\n",
    "        out_path = os.path.join(EMBEDDINGS_PATH, genie_version, subset_name)\n",
    "        os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "        (\n",
    "            subset_sample_ids,\n",
    "            subset_genes,\n",
    "        ) = genie.get_genes_and_samples_from_seq_assay_ids(\n",
    "            df_gp_wide, df_dcs_all, seq_assay_ids\n",
    "        )\n",
    "\n",
    "        df_dcs = df_dcs_all.loc[subset_sample_ids]\n",
    "        \n",
    "        \n",
    "        df_psm = df_psm_all[df_psm_all[\"SAMPLE_ID\"].isin(df_dcs.index)]\n",
    "        mut_sentences = genie.get_psm_sentences(df_psm)\n",
    "        mut_sentences = genie.filter_sentences_by_gene(mut_sentences, subset_genes)\n",
    "        df_dcs_mut = df_dcs.loc[mut_sentences.index].copy()\n",
    "        df_dcs_mut[\"mut_sentences\"] = mut_sentences\n",
    "\n",
    "        for embedding_size in EMBEDDING_SIZES:\n",
    "            print(embedding_size)\n",
    "\n",
    "            # mutations extended emebeddings\n",
    "            # ===========================================================\n",
    "            embds_mut = embedders.GenePpmiEmbeddings(\n",
    "                df_dcs_mut[\"mut_sentences\"],\n",
    "                subset_name,\n",
    "                min_unigram_weight=MIN_UNIGRAM_COUNT,\n",
    "                unigram_weighter=embedders.unigram_weighter_identity,\n",
    "                skipgram_weighter=embedders.skipgram_weighter_product,\n",
    "                embedding_size=embedding_size,\n",
    "            )\n",
    "            embds_mut.create_embeddings()\n",
    "            df_meta_extra = get_meta_extra(df_ras, embds_mut, unigram_name)\n",
    "            embds_mut.write_gene_projector_files(\n",
    "                out_path, f\"mut_{subset_name}\", unigram_name, df_meta_extra\n",
    "            )\n",
    "\n",
    "            # for mutations, remove weight from sentences for metadata\n",
    "            df_dcs_mut_meta = df_dcs_mut.copy()\n",
    "            df_dcs_mut_meta[\"mut_sentences\"] = df_dcs_mut_meta[\"mut_sentences\"].apply(\n",
    "                lambda x: [el[0] for el in x]\n",
    "            )\n",
    "            embds_mut.write_sample_projector_files(\n",
    "                out_path, f\"mut_{subset_name}\", unigram_name, df_dcs_mut_meta\n",
    "            )\n",
    "\n",
    "        \n",
    "        df_cna = df_cna_all[df_cna_all.index.isin(df_dcs.index)]\n",
    "        if df_cna.shape[0] < 10:\n",
    "            continue\n",
    "        cna_sentences = genie.get_cna_sentences(df_cna)\n",
    "        cna_sentences = genie.filter_sentences_by_gene(cna_sentences, subset_genes)\n",
    "        df_dcs_cna = df_dcs.loc[cna_sentences.index].copy()\n",
    "        df_dcs_cna[\"cna_sentences\"] = cna_sentences\n",
    "\n",
    "        for embedding_size in EMBEDDING_SIZES:\n",
    "            print(embedding_size)\n",
    "\n",
    "\n",
    "            # copy number alterations emebeddings\n",
    "            # ===========================================================\n",
    "            embds_cna = embedders.GenePpmiEmbeddings(\n",
    "                df_dcs_cna[\"cna_sentences\"],\n",
    "                subset_name,\n",
    "                min_unigram_weight=MIN_UNIGRAM_COUNT,\n",
    "                unigram_weighter=embedders.unigram_weighter_abs,\n",
    "                skipgram_weighter=embedders.skipgram_weighter_norm,\n",
    "                embedding_size=embedding_size,\n",
    "            )\n",
    "            embds_cna.create_embeddings()\n",
    "            df_meta_extra = get_meta_extra(df_ras, embds_cna, unigram_name)\n",
    "            embds_cna.write_gene_projector_files(\n",
    "                out_path, f\"cna_{subset_name}\", unigram_name, df_meta_extra\n",
    "            )\n",
    "            embds_cna.write_sample_projector_files(\n",
    "                out_path, f\"cna_{subset_name}\", unigram_name, df_dcs_cna\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ba2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"MSK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(EMBEDDINGS_PATH, genie_version, subset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = pd.read_csv(\n",
    "    os.path.join(in_path, f\"mut_{subset_name}_sample_100_vecs.tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ec588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_csv(os.path.join(in_path, f'mut_{subset_name}_sample_meta.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89baca9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea88c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae685e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce8464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
